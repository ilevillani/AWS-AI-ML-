!pip install -U pip
!pip install -U setuptools wheel
#!pip install -U "mxnet<2.0.0" bokeh==2.0.1
!pip install autogluon --no-cache-dir
# Without --no-cache-dir, smaller aws instances may have trouble installing
!pip install kaggle

# I have limited access to root
# Therefore, as suggested by SL, I created the .kaggle directory in the user's home directory
!mkdir -p ~/.kaggle

# Create the kaggle.json file
!touch ~/.kaggle/kaggle.json

# Set the correct permissions for the file
!chmod 600 ~/.kaggle/kaggle.json

# Fills in username and key from creating the kaggle account and API token file
import json
import os

kaggle_username = "ileanavillani"
kaggle_key = "57a447752d7d2809ab547f2cc4d1e7d3"

kaggle_json_path = os.path.expanduser("~/.kaggle/kaggle.json")
kaggle_json_path

# Save API token the kaggle.json file
with open(kaggle_json_path, "w") as f:
    f.write(json.dumps({"username": kaggle_username, "key": kaggle_key}))

# Downloading the dataset in compressed format (.zip)
!kaggle competitions download -c bike-sharing-demand
# Unzipping file. If already downloaded, the -o command overwrites the existing file
!unzip -o bike-sharing-demand.zip

# checks installation of autogluon
import pandas as pd
from autogluon.tabular import TabularPredictor

# Creates the train dataset in pandas by reading the csv
# Set the parsing of the datetime column so some of the `dt` features can be used in pandas later
train = pd.read_csv("train.csv",parse_dates=["datetime"])
train.head()

# Simple output of the train dataset to view some of the min/max/varition of the dataset features.
train.describe()

# Getting info regarding the datatypes present in the train dataset
train.info()

# Creates the test pandas dataframe in pandas by reading the csv. Also parsing the datetime
test = pd.read_csv("test.csv",parse_dates=["datetime"])
test.head()

# Creates the submission pandas dataframe in pandas by reading the csv. Also parsing the datetime
submission = pd.read_csv("sampleSubmission.csv",parse_dates=["datetime"])
submission.head()

predictor = TabularPredictor(label="count", eval_metric="root_mean_squared_error", learner_kwargs={'ignored_columns': ['casual', 'registered']}).fit(train_data=train, time_limit=600, presets="best_quality")

predictor.fit_summary()

# Above code output results and leaderboard
# Code below outputs a more visually appealing leaderboard, with horizontal bar plot which is clearer for long model names
predictor.leaderboard(silent=True).plot(kind="bar",x="model",y="score_val")

# Outputs leaderboard of top 5 models
predictor.leaderboard(silent=True).nlargest(5, "score_val")
